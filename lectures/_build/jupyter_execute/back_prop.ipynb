{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de991d5",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a498ed",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jax\n",
      "  Using cached jax-0.4.18-py3-none-any.whl (1.7 MB)\n",
      "Collecting jaxlib\n",
      "  Using cached jaxlib-0.4.18-cp39-cp39-win_amd64.whl (46.6 MB)\n",
      "Collecting ml-dtypes>=0.2.0\n",
      "  Using cached ml_dtypes-0.3.1-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\chenoi\\anaconda3\\lib\\site-packages (from jax) (4.13.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\chenoi\\anaconda3\\lib\\site-packages (from jax) (1.10.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\chenoi\\anaconda3\\lib\\site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\chenoi\\anaconda3\\lib\\site-packages (from jax) (1.25.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\chenoi\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.6->jax) (3.12.0)\n",
      "Installing collected packages: ml-dtypes, jaxlib, jax\n",
      "Successfully installed jax-0.4.18 jaxlib-0.4.18 ml-dtypes-0.3.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "# >>>>>>>>>>>>>>>>>>>>>> ERROR REPORT <<<<<<<<<<<<<<<<<<<<<<\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\gateways\\repodata\\__init__.py\", line 161, in conda_http_errors\n",
      "        yield\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\gateways\\repodata\\__init__.py\", line 127, in repodata\n",
      "        response.raise_for_status()\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n",
      "        raise HTTPError(http_error_msg, response=self)\n",
      "    requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://conda.anaconda.org/plotly/win-64/current_repodata.json\n",
      "    \n",
      "    During handling of the above exception, another exception occurred:\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 971, in json\n",
      "        return complexjson.loads(self.text, **kwargs)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\simplejson\\__init__.py\", line 525, in loads\n",
      "        return _default_decoder.decode(s)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\simplejson\\decoder.py\", line 372, in decode\n",
      "        obj, end = self.raw_decode(s)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\simplejson\\decoder.py\", line 402, in raw_decode\n",
      "        return self.scan_once(s, idx=_w(s, idx).end())\n",
      "    simplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "    \n",
      "    During handling of the above exception, another exception occurred:\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\exceptions.py\", line 1132, in __call__\n",
      "        return func(*args, **kwargs)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\cli\\main.py\", line 69, in main_subshell\n",
      "        exit_code = do_call(args, p)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\cli\\conda_argparse.py\", line 122, in do_call\n",
      "        return getattr(module, func_name)(args, parser)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\notices\\core.py\", line 116, in wrapper\n",
      "        return_value = func(*args, **kwargs)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\cli\\main_install.py\", line 20, in execute\n",
      "        install(args, parser, 'install')\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\cli\\install.py\", line 264, in install\n",
      "        unlink_link_transaction = solver.solve_for_transaction(\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\solve.py\", line 134, in solve_for_transaction\n",
      "        unlink_precs, link_precs = self.solve_for_diff(update_modifier, deps_modifier,\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\solve.py\", line 177, in solve_for_diff\n",
      "        final_precs = self.solve_final_state(update_modifier, deps_modifier, prune, ignore_pinned,\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\solve.py\", line 282, in solve_final_state\n",
      "        ssc = self._collect_all_metadata(ssc)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\common\\io.py\", line 84, in decorated\n",
      "        return f(*args, **kwds)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\solve.py\", line 449, in _collect_all_metadata\n",
      "        index, r = self._prepare(prepared_specs)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\solve.py\", line 1064, in _prepare\n",
      "        reduced_index = get_reduced_index(self.prefix, self.channels,\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\index.py\", line 267, in get_reduced_index\n",
      "        new_records = SubdirData.query_all(spec, channels=channels, subdirs=subdirs,\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\subdir_data.py\", line 169, in query_all\n",
      "        result = tuple(chain.from_iterable(executor.map(subdir_query, channel_urls)))\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 609, in result_iterator\n",
      "        yield fs.pop().result()\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 446, in result\n",
      "        return self.__get_result()\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "        raise self._exception\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "        result = self.fn(*self.args, **self.kwargs)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\subdir_data.py\", line 158, in subdir_query\n",
      "        return tuple(\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\subdir_data.py\", line 174, in query\n",
      "        self.load()\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\subdir_data.py\", line 264, in load\n",
      "        _internal_state = self._load()\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\core\\subdir_data.py\", line 366, in _load\n",
      "        raw_repodata_str = self._repo.repodata(cache.state)  # type: ignore\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\gateways\\repodata\\__init__.py\", line 127, in repodata\n",
      "        response.raise_for_status()\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\contextlib.py\", line 137, in __exit__\n",
      "        self.gen.throw(typ, value, traceback)\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\gateways\\repodata\\__init__.py\", line 208, in conda_http_errors\n",
      "        raise RepodataIsEmpty(\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\conda\\exceptions.py\", line 462, in __init__\n",
      "        body = response.json()\n",
      "      File \"C:\\Users\\chenoi\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 975, in json\n",
      "        raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "    requests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "`$ C:\\Users\\chenoi\\anaconda3\\Scripts\\conda-script.py install -y -c plotly plotly plotly-orca retrying`\n",
      "\n",
      "  environment variables:\n",
      "             AMDRMSDKPATH=C:\\Program Files\\AMD\\RyzenMasterSDK\\\n",
      "                 CIO_TEST=<not set>\n",
      "                CONDA_EXE=C:\\Users\\chenoi\\anaconda3\\condabin\\..\\Scripts\\conda.exe\n",
      "               CONDA_EXES=\"C:\\Users\\chenoi\\anaconda3\\condabin\\..\\Scripts\\conda.exe\"\n",
      "               CONDA_ROOT=C:\\Users\\chenoi\\anaconda3\n",
      "           CURL_CA_BUNDLE=<not set>\n",
      "                 HOMEPATH=\\Users\\chenoi\n",
      "               LD_PRELOAD=<not set>\n",
      "                     PATH=D:\\Program Files\\Bin\\;C:\\Program Files\\Microsoft\\jdk-11.0.16.101-hotsp\n",
      "                          ot\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Wind\n",
      "                          ows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\P\n",
      "                          rogram Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\Bandizip\\;D:\n",
      "                          \\Git\\cmd;D:\\Git\\usr\\bin;C:\\Users\\chenoi\\anaconda3\\Library\\bin;C:\\Users\n",
      "                          \\chenoi\\anaconda3\\python;C:\\Users\\chenoi\\anaconda3\\Scripts;C:\\Users\\ch\n",
      "                          enoi\\anaconda3;C:\\Users\\chenoi\\anaconda3\\condabin;C:\\Program Files\\Jav\n",
      "                          a\\jdk1.8.0_202\\BIN;D:\\Download\\hugo\\bin;C:\\Users\\chenoi\\AppData\\Roamin\n",
      "                          g\\nvm;C:\\Program Files\\nodejs;C:\\Program Files\\NVIDIA\n",
      "                          Corporation\\NVIDIA NvDLISR;C:\\Program Files (x86)\\NVIDIA\n",
      "                          Corporation\\PhysX\\Common;C:\\mingw64\\bin;D:\\Program\n",
      "                          Files\\Graphviz\\bin;C:\\Program Files\\dotnet\\;D:\\Program\n",
      "                          Files\\;C:\\Program Files\\Pandoc\\;C:\\Program\n",
      "                          Files\\MiKTeX\\miktex\\bin\\x64\\;C:\\Program\n",
      "                          Files\\Google\\Chrome\\Application;D:\\Program\n",
      "                          Files\\poppler-23.07.0\\Library\\bin;D:\\Program\n",
      "                          Files\\tesseract.exe;C:\\Users\\chenoi\\.poetry\\bin;C:\\Program\n",
      "                          Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\chenoi\\AppData\\Local\\Microso\n",
      "                          ft\\WindowsApps;C:\\Program Files\\JetBrains\\PyCharm\n",
      "                          2022.3\\bin;;C:\\Users\\chenoi\\AppData\\Local\\Programs\\Microsoft VS\n",
      "                          Code\\bin;C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.3\\bin;;C:\\Users\n",
      "                          \\chenoi\\AppData\\Roaming\\npm;C:\\Users\\chenoi\\AppData\\Local\\GitHubDeskto\n",
      "                          p\\bin;C:\\Users\\chenoi\\AppData\\Roaming\\nvm;C:\\Program\n",
      "                          Files\\nodejs;C:\\Program Files\\JetBrains\\WebStorm\n",
      "                          2022.3.1\\bin;;C:\\Users\\chenoi\\AppData\\Local\\Programs\\oh-my-\n",
      "                          posh\\bin;C:\\Program Files\\heroku\\bin;C:\\Program Files\\JetBrains\\CLion\n",
      "                          2021.3.4\\bin;;C:\\Program Files\\JetBrains\\JetBrains Rider\n",
      "                          2022.3.2\\bin;;C:\\Users\\chenoi\\.dotnet\\tools;C:\\Program\n",
      "                          Files\\MiKTeX\\miktex\\bin\\x64;\n",
      "         POSH_THEMES_PATH=C:\\Users\\chenoi\\AppData\\Local\\Programs\\oh-my-posh\\themes\n",
      "             PSMODULEPATH=C:\\Program Files\\WindowsPowerShell\\Modules;C:\\Windows\\system32\\Windows\n",
      "                          PowerShell\\v1.0\\Modules\n",
      "       REQUESTS_CA_BUNDLE=<not set>\n",
      "            SSL_CERT_FILE=<not set>\n",
      "\n",
      "     active environment : None\n",
      "       user config file : C:\\Users\\chenoi\\.condarc\n",
      " populated config files : C:\\Users\\chenoi\\.condarc\n",
      "          conda version : 23.3.0\n",
      "    conda-build version : 3.22.0\n",
      "         python version : 3.9.13.final.0\n",
      "       virtual packages : __archspec=1=x86_64\n",
      "                          __cuda=12.2=0\n",
      "                          __win=0=0\n",
      "       base environment : C:\\Users\\chenoi\\anaconda3  (writable)\n",
      "      conda av data dir : C:\\Users\\chenoi\\anaconda3\\etc\\conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://conda.anaconda.org/plotly/win-64\n",
      "                          https://conda.anaconda.org/plotly/noarch\n",
      "                          https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\Users\\chenoi\\anaconda3\\pkgs\n",
      "                          C:\\Users\\chenoi\\.conda\\pkgs\n",
      "                          C:\\Users\\chenoi\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\Users\\chenoi\\anaconda3\\envs\n",
      "                          C:\\Users\\chenoi\\.conda\\envs\n",
      "                          C:\\Users\\chenoi\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/23.3.0 requests/2.31.0 CPython/3.9.13 Windows/10 Windows/10.0.22621\n",
      "          administrator : False\n",
      "             netrc file : C:\\Users\\chenoi/.netrc\n",
      "           offline mode : False\n",
      "\n",
      "\n",
      "An unexpected error has occurred. Conda has prepared the above report.\n",
      "\n",
      "Upload successful.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jax jaxlib\n",
    "!conda install -y -c plotly plotly plotly-orca retrying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d76b8",
   "metadata": {},
   "source": [
    "```{note}\n",
    "If you are running this on Google Colab the above cell will \n",
    "present an error. This is because Google Colab doesn't use Anaconda to manage\n",
    "the Python packages. However this lecture will still execute as Google Colab\n",
    "has `plotly` installed.\n",
    "```\n",
    "\n",
    "## Overview\n",
    "\n",
    "Substantial parts of **machine learning** and **artificial intelligence** are about \n",
    "\n",
    "* approximating an unknown function with a known function\n",
    "* estimating the known function from a set of data on the left- and right-hand variables\n",
    "\n",
    "This lecture describes the structure of a plain vanilla **artificial neural network**  (ANN) of a type that is widely used to \n",
    "approximate a function $f$ that maps   $x$ in  a space $X$ into  $y$ in a space $Y$.  \n",
    "\n",
    "To introduce elementary concepts, we study an example in which $x$ and $y$ are scalars.\n",
    "\n",
    "We'll describe the following concepts that are brick and mortar for neural networks:\n",
    " * a neuron\n",
    " * an activation function\n",
    " * a network of neurons \n",
    " * A neural network as a composition of functions\n",
    " * back-propagation and its relationship  to the chain rule of differential calculus\n",
    " \n",
    "\n",
    "## A Deep (but not Wide) Artificial Neural Network\n",
    "\n",
    "We describe a  \"deep\" neural network of \"width\" one.  \n",
    "\n",
    "**Deep** means that the network composes a large number of functions organized into nodes of a graph.\n",
    "\n",
    "**Width** refers to the number of right hand  side variables on the right hand side of the function being approximated.\n",
    "\n",
    "Setting \"width\" to one means that the network    composes just univariate functions.\n",
    "\n",
    "Let $x \\in \\mathbb{R}$ be a scalar and $y \\in \\mathbb{R}$ be another scalar.\n",
    "\n",
    "We assume  that $y$ is  a nonlinear function of $x$:\n",
    "\n",
    "$$\n",
    "y = f(x)\n",
    "$$\n",
    "\n",
    "We want to approximate  $f(x)$ with another function that we define recursively.\n",
    "\n",
    "For a network of depth $N \\geq 1$, each **layer** $i =1, \\ldots N$ consists of \n",
    "\n",
    "* an input $x_i$\n",
    "\n",
    "* an **affine function** $w_i x_i + bI$, where $w_i$ is a scalar **weight** placed on the input $x_i$ and $b_i$ is a scalar **bias**\n",
    "\n",
    "* an **activation function** $h_i$ that takes $(w_i x_i + b_i)$ as an argument and produces an output $x_{i+1}$\n",
    "   \n",
    "     \n",
    "An example of an activation function $h$ is the **sigmoid** function\n",
    "\n",
    "$$\n",
    "h (z) = \\frac{1}{1 + e^{-z}} \n",
    "$$\n",
    "\n",
    "\n",
    "Another popular activation function is the **rectified linear unit** (ReLU) function\n",
    "\n",
    "$$\n",
    "h(z) = \\max (0, z) \n",
    "$$\n",
    "\n",
    "\n",
    "Yet another activation function is the identity function\n",
    "\n",
    "$$ \n",
    "h(z) = z \n",
    "$$\n",
    "\n",
    "As activation functions below, we'll use the sigmoid function for layers $1$ to $N-1$ and the identity function for  layer $N$.\n",
    "\n",
    "To approximate a function $f(x)$ we construct   $\\hat f(x)$  by proceeding as follows.\n",
    "\n",
    "Let \n",
    "\n",
    "$$\n",
    " l_{i}\\left(x\\right)=w_{i}x+b_{i} . \n",
    "$$ \n",
    "\n",
    "We construct  $\\hat f$ by iterating on compositions of functions $h_i \\circ l_i$:\n",
    "\n",
    "$$\n",
    "f(x)\\approx\\hat{f}(x)=h_{N}\\circ l_{N}\\circ h_{N-1}\\circ l_{1}\\circ\\cdots\\circ h_{1}\\circ l_{1}(x)\n",
    "$$\n",
    "\n",
    "If $N >1$, we call the right side a \"deep\" neural net.\n",
    "\n",
    "The larger is the integer $N$, the \"deeper\" is the neural net.\n",
    "\n",
    "Evidently,  if we know  the parameters $\\{w_i, b_i\\}_{i=1}^N$, then we can compute\n",
    "$\\hat f(x)$ for a given $x = \\tilde x$ by iterating on the recursion\n",
    "\n",
    "$$\n",
    "x_{i+1} = h_i \\circ l_i(x_i) , \\quad, i = 1, \\ldots N\n",
    "$$ (eq:recursion)\n",
    "\n",
    "starting from $x_1 = \\tilde x$.  \n",
    "\n",
    "The value of $x_{N+1}$ that emerges from this iterative scheme\n",
    "equals $\\hat f(\\tilde x)$.\n",
    "\n",
    "## Calibrating  Parameters\n",
    "\n",
    "\n",
    "We now consider a  neural network like the one describe above  with width 1, depth $N$,  and activation functions $h_{i}$ for $1\\leqslant i\\leqslant N$ that map $\\mathbb{R}$ into itself.\n",
    "\n",
    "\n",
    "Let $\\left\\{ \\left(w_{i},b_{i}\\right)\\right\\} _{i=1}^{N}$ denote a sequence of weights and biases.\n",
    "\n",
    "As mentioned above, for a given input $x_{1}$, our approximating function $\\hat f$ evaluated\n",
    "at $x_1$ equals the \"output\" $x_{N+1}$ from our network that  can be computed by iterating on $x_{i+1}=h_{i}\\left(w_{i}x_{i}+b_{i}\\right)$.\n",
    "\n",
    "For a given **prediction** $\\hat{y} (x) $ and **target** $y= f(x)$, consider the loss function\n",
    "\n",
    "$$\n",
    "\\mathcal{L} \\left(\\hat{y},y\\right)(x)=\\frac{1}{2}\\left(\\hat{y}-y\\right)^{2}(x) .\n",
    "$$\n",
    "\n",
    "This criterion is a function of the parameters $\\left\\{ \\left(w_{i},b_{i}\\right)\\right\\} _{i=1}^{N}$\n",
    "and the point $x$.\n",
    "\n",
    "We're interested in solving the following problem:\n",
    "\n",
    "$$\n",
    "\\min_{\\left\\{ \\left(w_{i},b_{i}\\right)\\right\\} _{i=1}^{N}} \\int {\\mathcal L}\\left(x_{N+1},y\\right)(x) d \\mu(x)\n",
    "$$\n",
    "\n",
    "where $\\mu(x)$ is some measure of  points $x \\in \\mathbb{R}$ over which we want a good approximation $\\hat f(x)$ to $f(x)$.\n",
    "\n",
    "Stack  weights and biases into a vector of parameters $p$:\n",
    "\n",
    "$$ \n",
    "p = \\begin{bmatrix}     \n",
    "  w_1 \\cr \n",
    "  b_1 \\cr\n",
    "  w_2 \\cr\n",
    "  b_2 \\cr\n",
    "  \\vdots \\cr\n",
    "  w_N \\cr\n",
    "  b_N \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Applying a \"poor man's version\" of a **stochastic gradient descent** algorithm for finding a zero of a function leads to the following update rule for parameters:\n",
    "\n",
    "$$\n",
    "p_{k+1}=p_k-\\alpha\\frac{d \\mathcal{L}}{dx_{N+1}}\\frac{dx_{N+1}}{dp_k}\n",
    "$$ (eq:sgd)\n",
    "\n",
    "where $\\frac{d {\\mathcal L}}{dx_{N+1}}=-\\left(x_{N+1}-y\\right)$ and $\\alpha > 0 $ is a step size.\n",
    "\n",
    "(See [this](https://en.wikipedia.org/wiki/Gradient_descent#Description) and [this](https://en.wikipedia.org/wiki/Newton%27s_method) to gather insights about how stochastic gradient descent\n",
    "relates to Newton's method.)\n",
    "\n",
    "To implement one step of this parameter update rule, we want  the vector of derivatives $\\frac{dx_{N+1}}{dp_k}$.\n",
    "\n",
    "In the neural network literature, this step is accomplished by what is known as **back propagation**.\n",
    "\n",
    "## Back Propagation and the Chain Rule\n",
    "\n",
    "Thanks to  properties of\n",
    "\n",
    "* the chain and product rules for differentiation from differential calculus, and\n",
    "\n",
    "* lower triangular matrices\n",
    "   \n",
    "back propagation can actually be  accomplished in one step by\n",
    "\n",
    " *  inverting a lower triangular matrix,  and \n",
    " \n",
    " * matrix multiplication\n",
    "\n",
    "(This idea  is from the last 7 minutes of this great youtube video by MIT's Alan Edelman)\n",
    "\n",
    "```{youtube} rZS2LGiurKY\n",
    "```\n",
    "\n",
    "\n",
    "Here goes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Define the derivative of $h(z)$ with respect to $z$ evaluated at $z = z_i$  as $\\delta_i$:\n",
    "\n",
    "$$\n",
    "\\delta_i = \\frac{d}{d z} h(z)|_{z=z_i}\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$\n",
    "\\delta_{i}=h'\\left(w_{i}x_{i}+b_{i}\\right). \n",
    "$$ \n",
    "\n",
    "Repeated application of the chain rule and product rule to our recursion {eq}`eq:recursion` allows us to obtain:\n",
    "\n",
    "$$\n",
    "dx_{i+1}=\\delta_{i}\\left(dw_{i}x_{i}+w_{i}dx_{i}+b_{i}\\right)\n",
    "$$\n",
    "\n",
    "After imposing $dx_{1}=0$, we get the following system of equations:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}\n",
    "dx_{2}\\\\\n",
    "\\vdots\\\\\n",
    "dx_{N+1}\n",
    "\\end{array}\\right)=\\underbrace{\\left(\\begin{array}{ccccc}\n",
    "\\delta_{1}w_{1} & \\delta_{1} & 0 & 0 & 0\\\\\n",
    "0 & 0 & \\ddots & 0 & 0\\\\\n",
    "0 & 0 & 0 & \\delta_{N}w_{N} & \\delta_{N}\n",
    "\\end{array}\\right)}_{D}\\left(\\begin{array}{c}\n",
    "dw_{1}\\\\\n",
    "db_{1}\\\\\n",
    "\\vdots\\\\\n",
    "dw_{N}\\\\\n",
    "db_{N}\n",
    "\\end{array}\\right)+\\underbrace{\\left(\\begin{array}{cccc}\n",
    "0 & 0 & 0 & 0\\\\\n",
    "w_{2} & 0 & 0 & 0\\\\\n",
    "0 & \\ddots & 0 & 0\\\\\n",
    "0 & 0 & w_{N} & 0\n",
    "\\end{array}\\right)}_{L}\\left(\\begin{array}{c}\n",
    "dx_{2}\\\\\n",
    "\\vdots\\\\\n",
    "dx_{N+1}\n",
    "\\end{array}\\right)\n",
    "$$ \n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "d x = D dp + L dx\n",
    "$$\n",
    "\n",
    "which implies that\n",
    "\n",
    "$$\n",
    "dx = (I -L)^{-1} D dp\n",
    "$$\n",
    "\n",
    "which in turn  implies\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}\n",
    "dx_{N+1}/dw_{1}\\\\\n",
    "dx_{N+1}/db_{1}\\\\\n",
    "\\vdots\\\\\n",
    "dx_{N+1}/dw_{N}\\\\\n",
    "dx_{N+1}/db_{N}\n",
    "\\end{array}\\right)=e_{N}\\left(I-L\\right)^{-1}D.\n",
    "$$\n",
    "\n",
    "We can then solve the above problem by applying our update for $p$ multiple times for a collection of input-output pairs $\\left\\{ \\left(x_{1}^{i},y^{i}\\right)\\right\\} _{i=1}^{M}$ that we'll call our \"training set\".\n",
    "\n",
    "\n",
    "\n",
    "## Training Set\n",
    "\n",
    "Choosing a  training set amounts to a choice of measure $\\mu$ in the above  formulation of our  function approximation problem as a minimization problem.\n",
    "\n",
    "In this spirit,  we shall use a uniform grid of, say, 50 or 200 points. \n",
    "\n",
    "There are many possible approaches to the minimization  problem posed above:\n",
    "\n",
    "* batch gradient descent in which you use an average gradient over the training set\n",
    "\n",
    "* stochastic gradient descent in which you sample points randomly and use individual gradients\n",
    "\n",
    "* something in-between (so-called \"mini-batch gradient descent\")\n",
    " \n",
    "The update rule {eq}`eq:sgd` described above  amounts  to a stochastic gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04d5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, jacfwd, vmap\n",
    "from jax import random\n",
    "import jax\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6feab386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_layer_params(m, n, key, scale=1.):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7abfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_xδw_seq(params, x):\n",
    "    # Initialize arrays\n",
    "    δ = jnp.zeros(len(params))\n",
    "    xs = jnp.zeros(len(params) + 1)\n",
    "    ws = jnp.zeros(len(params))\n",
    "    bs = jnp.zeros(len(params))\n",
    "    \n",
    "    h = jax.nn.sigmoid\n",
    "    \n",
    "    xs = xs.at[0].set(x)\n",
    "    for i, (w, b) in enumerate(params[:-1]):\n",
    "        output = w * xs[i] + b\n",
    "        activation = h(output[0, 0])\n",
    "        \n",
    "        # Store elements\n",
    "        δ = δ.at[i].set(grad(h)(output[0, 0]))\n",
    "        ws = ws.at[i].set(w[0, 0])\n",
    "        bs = bs.at[i].set(b[0])\n",
    "        xs = xs.at[i+1].set(activation)\n",
    "\n",
    "    final_w, final_b = params[-1]\n",
    "    preds = final_w * xs[-2] + final_b\n",
    "    \n",
    "    # Store elements\n",
    "    δ = δ.at[-1].set(1.)\n",
    "    ws = ws.at[-1].set(final_w[0, 0])\n",
    "    bs = bs.at[-1].set(final_b[0])\n",
    "    xs = xs.at[-1].set(preds[0, 0])\n",
    "    \n",
    "    return xs, δ, ws, bs\n",
    "    \n",
    "\n",
    "def loss(params, x, y):\n",
    "    xs, δ, ws, bs = compute_xδw_seq(params, x)\n",
    "    preds = xs[-1]\n",
    "    \n",
    "    return 1 / 2 * (y - preds) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efec3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 3  # Number of layers\n",
    "layer_sizes = [1, ] * (N + 1)\n",
    "param_scale = 0.1\n",
    "step_size = 0.01\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0dea5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "y = 3\n",
    "xs, δ, ws, bs = compute_xδw_seq(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853fea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxs_ad = jacfwd(lambda params, x: compute_xδw_seq(params, x)[0], argnums=0)(params, x)\n",
    "dxs_ad_mat = jnp.block([dx.reshape((-1, 1)) for dx_tuple in dxs_ad for dx in dx_tuple ])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c150eb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[8.5726520e-03, 4.0850646e-04, 6.1021698e-01],\n",
       "       [1.7145304e-03, 2.3785222e-01, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.block([[δ * xs[:-1]], [δ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e7994e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = jnp.diag(δ * ws, k=-1)\n",
    "L = L[1:, 1:]\n",
    "\n",
    "D = jax.scipy.linalg.block_diag(*[row.reshape((1, 2)) for row in jnp.block([[δ * xs[:-1]], [δ]]).T])\n",
    "\n",
    "dxs_la = jax.scipy.linalg.solve_triangular(jnp.eye(N) - L, D, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7058d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the `dx` generated by the linear algebra method\n",
    "# are the same as the ones generated using automatic differentiation\n",
    "jnp.max(jnp.abs(dxs_ad_mat - dxs_la))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8184203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_loss_ad = jnp.block([dx.reshape((-1, 1)) for dx_tuple in grad(loss)(params, x, y) for dx in dx_tuple ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78dd40df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.4901161e-08, dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the gradient of the loss is the same for both approaches\n",
    "jnp.max(jnp.abs(-(y - xs[-1]) * dxs_la[-1] - grad_loss_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a1a455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update_ad(params, x, y):\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    return [(w - step_size * dw, b - step_size * db)\n",
    "          for (w, b), (dw, db) in zip(params, grads)]\n",
    "\n",
    "@jit\n",
    "def update_la(params, x, y):\n",
    "    xs, δ, ws, bs = compute_xδw_seq(params, x)\n",
    "    N = len(params)\n",
    "    L = jnp.diag(δ * ws, k=-1)\n",
    "    L = L[1:, 1:]\n",
    "\n",
    "    D = jax.scipy.linalg.block_diag(*[row.reshape((1, 2)) for row in jnp.block([[δ * xs[:-1]], [δ]]).T])\n",
    "    \n",
    "    dxs_la = jax.scipy.linalg.solve_triangular(jnp.eye(N) - L, D, lower=True)\n",
    "    \n",
    "    grads = -(y - xs[-1]) * dxs_la[-1]\n",
    "    \n",
    "    return [(w - step_size * dw, b - step_size * db) \n",
    "            for (w, b), (dw, db) in zip(params, grads.reshape((-1, 2)))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9374ebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Array([[-1.3489482]], dtype=float32), Array([0.37956238], dtype=float32)),\n",
       " (Array([[-0.00782906]], dtype=float32), Array([0.44972023], dtype=float32)),\n",
       " (Array([[0.22937916]], dtype=float32), Array([-0.04793657], dtype=float32))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that both updates are the same\n",
    "update_la(params, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62586b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Array([[-1.3489482]], dtype=float32), Array([0.37956238], dtype=float32)),\n",
       " (Array([[-0.00782906]], dtype=float32), Array([0.44972023], dtype=float32)),\n",
       " (Array([[0.22937916]], dtype=float32), Array([-0.04793657], dtype=float32))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_ad(params, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb01d5b",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "Consider the function \n",
    "\n",
    "$$\n",
    "f\\left(x\\right)=-3x+2\n",
    "$$\n",
    "\n",
    "on $\\left[0.5,3\\right]$. \n",
    "\n",
    "We use a uniform grid of 200 points and update the parameters for each point on the grid 300 times. \n",
    "\n",
    "$h_{i}$ is the sigmoid activation function for all layers except the final one for which we use the identity function and $N=3$.\n",
    "\n",
    "Weights are initialized randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d27bd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return -3 * x + 2\n",
    "\n",
    "M = 200\n",
    "grid = jnp.linspace(0.5, 3, num=M)\n",
    "f_val = f(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5f98aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = jnp.arange(M)\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "def train(params, grid, f_val, key, num_epochs=300):\n",
    "    for epoch in range(num_epochs):\n",
    "        key, _ = random.split(key)\n",
    "        random_permutation = random.permutation(random.PRNGKey(1), indices)\n",
    "        for x, y in zip(grid[random_permutation], f_val[random_permutation]):\n",
    "            params = update_la(params, x, y)\n",
    "            \n",
    "    return params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f21183c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 3  # Number of layers\n",
    "layer_sizes = [1, ] * (N + 1)\n",
    "params_ex1 = init_network_params(layer_sizes, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17969eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "params_ex1 = train(params_ex1, grid, f_val, key, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffeaa6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = vmap(compute_xδw_seq, in_axes=(None, 0))(params_ex1, grid)[0][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18644e85",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9592\\2707810712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Export to PNG file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# fig.show() will provide interactive plot when running\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# notebook locally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\plotly\\basedatatypes.py\u001b[0m in \u001b[0;36mto_image\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3756\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3758\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3760\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\plotly\\io\\_kaleido.py\u001b[0m in \u001b[0;36mto_image\u001b[1;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;31m# ---------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[0mfig_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_coerce_fig_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     img_bytes = scope.transform(\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[0mfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kaleido\\scopes\\plotly.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, figure, format, width, height, scale)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# Transform in using _perform_transform rather than superclass so we can access the full\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;31m# response dict, including error codes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response = self._perform_transform(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kaleido\\scopes\\base.py\u001b[0m in \u001b[0;36m_perform_transform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \"\"\"\n\u001b[0;32m    292\u001b[0m         \u001b[1;31m# Ensure that kaleido subprocess is running\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_kaleido\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# Perform export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kaleido\\scopes\\base.py\u001b[0m in \u001b[0;36m_ensure_kaleido\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                     \u001b[1;31m# Read startup message and check for errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                     \u001b[0mstartup_response_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstartup_response_string\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                         message = (\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=f_val, name=r'$-3x+2$'))\n",
    "fig.add_trace(go.Scatter(x=grid, y=predictions, name='Approximation'))\n",
    "\n",
    "# Export to PNG file\n",
    "Image(fig.to_image(format=\"png\"))\n",
    "# fig.show() will provide interactive plot when running\n",
    "# notebook locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed6df6",
   "metadata": {},
   "source": [
    "## How Deep? \n",
    "\n",
    "It  is  fun to think about how deepening the neural net for the above example affects the quality of  approximation \n",
    "\n",
    "\n",
    "* If the network is too deep, you'll run into the [vanishing gradient problem](http://neuralnetworksanddeeplearning.com/chap5.html)\n",
    "* Other parameters such as the step size and the number of epochs can be as  important or more important than the number of layers in the situation considered in this lecture.\n",
    "* Indeed, since $f$ is a linear function of $x$, a one-layer network with the identity map as an activation would probably work best. \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "## Example 2\n",
    "\n",
    "We use the same setup as for the previous example with\n",
    "\n",
    "$$\n",
    "f\\left(x\\right)=\\log\\left(x\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return jnp.log(x)\n",
    "\n",
    "grid = jnp.linspace(0.5, 3, num=M)\n",
    "f_val = f(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 1  # Number of layers\n",
    "layer_sizes = [1, ] * (N + 1)\n",
    "params_ex2_1 = init_network_params(layer_sizes, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 2  # Number of layers\n",
    "layer_sizes = [1, ] * (N + 1)\n",
    "params_ex2_2 = init_network_params(layer_sizes, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 3  # Number of layers\n",
    "layer_sizes = [1, ] * (N + 1)\n",
    "params_ex2_3 = init_network_params(layer_sizes, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ex2_1 = train(params_ex2_1, grid, f_val, key, num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e13000",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ex2_2 = train(params_ex2_2, grid, f_val, key, num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ex2_3 = train(params_ex2_3, grid, f_val, key, num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = vmap(compute_xδw_seq, in_axes=(None, 0))(params_ex2_1, grid)[0][:, -1]\n",
    "predictions_2 = vmap(compute_xδw_seq, in_axes=(None, 0))(params_ex2_2, grid)[0][:, -1]\n",
    "predictions_3 = vmap(compute_xδw_seq, in_axes=(None, 0))(params_ex2_3, grid)[0][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c673fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=grid, y=f_val, name=r'$\\log{x}$'))\n",
    "fig.add_trace(go.Scatter(x=grid, y=predictions_1, name='One-layer neural network'))\n",
    "fig.add_trace(go.Scatter(x=grid, y=predictions_2, name='Two-layer neural network'))\n",
    "fig.add_trace(go.Scatter(x=grid, y=predictions_3, name='Three-layer neural network'))\n",
    "\n",
    "# Export to PNG file\n",
    "Image(fig.to_image(format=\"png\"))\n",
    "# fig.show() will provide interactive plot when running\n",
    "# notebook locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2247c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to check that gpu is activated in environment\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846d94e",
   "metadata": {},
   "source": [
    "```{note}\n",
    "**Cloud Environment:** This lecture site is built in a server environment that doesn't have access to a `gpu`\n",
    "If you run this lecture locally this lets you know where your code is being executed, either\n",
    "via the `cpu` or the `gpu`\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   12,
   16,
   21,
   306,
   315,
   328,
   368,
   377,
   383,
   388,
   392,
   401,
   407,
   411,
   416,
   441,
   446,
   448,
   466,
   475,
   489,
   496,
   501,
   505,
   514,
   536,
   544,
   551,
   558,
   565,
   569,
   573,
   577,
   583,
   596,
   601
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}